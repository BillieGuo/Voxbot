lmp_config:
    env:
        # map_size: 100
        # num_waypoints_per_plan: 10000  # set to a large number since we only do open loop for sim
        # max_plan_iter: 1
        # visualize: True
    lmps:
        coder: # high-level interpreter
            name: 'coder'
            heirarchy: 'high'
            # model: 'llama3-8B-instruct-official-fineTuned'
            adapter:  # leave empty if no adapter is used
            max_new_tokens: 512
            # sys_prompts: 'coder_sys_prompt.txt'
            # user_prompts: 'coder_user_prompt.txt'
            load_in_4bit: False

            # test / demo
            model: 'gpt-4'
            sys_prompts: 'test_sys.txt'
            user_prompts: 'test_user.txt'

        planner: # low-level planner
            name: 'planner'
            heirarchy: 'low'
            # model: 'llama3-8B-instruct-official-fineTuned'
            model: 'gpt-4'
            adapter:  # leave empty if no adapter is used
            max_new_tokens: 512
            load_in_4bit: True
            # sys_prompts: 'planner_sys_prompt.txt'
            # user_prompts: 'planner_user_prompt.txt'
            
            # test / demo
            sys_prompts: 'demo_sys.txt'
            user_prompts: 'demo_user.txt'
            
        # arm: # low-level executor
        #     name: 'arm'
        #     heirarchy: 'low'
        #     model: 'llama3-8B-instruct-official-fineTuned'
        #     adapter:  # leave empty if no adapter is used
        #     max_new_tokens: 512
        #     load_in_4bit: True
        #     sys_prompts: 'arm_sys_prompt.txt'
        #     user_prompts: 'arm_user_prompt.txt'
            
        test:
            name: 'test'
            heirarchy: 'preview'
            model: 'llama3-8B-instruct-official-fineTuned'
            adapter:  # leave empty if no adapter is used
            max_new_tokens: 1024
            load_in_4bit: False
            sys_prompts: 'test_previewer_sys_prompt.txt'
            user_prompts: 'test_previewer_user_prompt.txt'